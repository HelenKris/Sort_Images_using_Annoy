
## Introduction

Если у у вас стоит задача глубокий анализ и систематизацию собранного датасета изображений для дальнейшей разметки, то данный скрипт поможет вам в вашей работе с датасетом.
Зачем проводить глубокое исследование и разделение обучающего датасета?
Во-первых, для того чтобы обеспечить наличие в данных четырех главных характеристик качественных данных для обучения ML моделей:
1.	Релевантность (relevancy) — набор данных должен содержать только те признаки, которые предоставляют модели значимую информацию. Выявление важных признаков — сложная задача, требующая знания области и чёткого понимания того, какие признаки стоит учитывать, а какие нужно устранить. Кластеризация данных помогает удалить из набора нерелевантные данные целыми группами объектов.
2.	Постоянство (consistency) — схожие примеры должны иметь схожие метки, обеспечивая однородность набора данных. Для повышения автоматизации ручной разметки разметчикам лучше давать данные кластерами, а не разнородные. Или давать по несколько объектов в кластере на живую разметку, на них обучать модель и с помощью модели делать предразметку остальных экземпляров класса.
3.	Однородность (uniformity) — значения всех атрибутов должны быть сравнимыми для всех данных. Неравномерности или наличие выбросов в наборах данных отрицательно влияют на качество данных обучения. Разделение на кластеры поможет определить выбросы, эти объекты не будут включены ни в одну выборку. Далее эти нужно будет анализировать на предмет удаления из выборки как нерелевантных, либо дополнять их как возможные пограничные случаи, чтобы обеспечить полноту обучающего набора (см. следующий пункт).
4.	Полнота (comprehensiveness) — набор данных должен содержать достаточное количество параметров или признаков, чтобы не осталось неохваченных пограничных случаев. Набор данных должен содержать достаточно сэмплов этих пограничных случаев, чтобы модель могла обучиться и им.

## How to start?
1. Все изображения для анализа и систематизации должны находится в папке "all"
2. Вы можете сначала запустить скрипт search_image.py, чтобы получить все Annoy indexes
3. Затем запустить find_similar_images.py, чтобы получить для каждой фотографии свой кластер из похожих изображений из 24 штук (+исходное), это количество можно изменить в скрипте в строке nns = annoy_index.get_nns_by_vector(output_tensor[0], 24 ). Просмотреть, какие кластеры вас интересуют и на какие вы бы хотели расформировать свой датсет.
4. Перенести фотографии выбранных кластеров в папку find_similarities (по одной - первой, например, фотографии из кластера) и запустить скрипт find_and_move.py, в результате которого в корневой папке должны появиться папки с рассортированными кластерами фотографий (folder_1, folder_2....примеры, полученные по результату сортировки 4 фотографий)

## Пример собранных в датасете похожих изображений в одной подгруппе в ImageDump
![image_0](https://github.com/HelenKris/Sort_Images_using_Annoy/assets/128362457/bd038bfa-1fda-4fdf-ae65-6475befb1fd2)

## Project Structure
```
Sort_Images_using_Annoy/
├── search_image.py --формирует Annoy index для каждого изображения в папке all и сохраняет все индексы в файле paintings_index.ann, используя предварительно обученную модель в PyTorch и Spotify Annoy
├── find_similar_images.py  --формирует по каждому изображению image_grid из 25 похожих изображений (можно менять количество) для целей эксплоративного визуального анализа датасета
├── find_and_move.py  --производит поиск по сходству изображений и разносит группы схожих фотографий по разным папкам
├── all  -- папка со всеми изображениями датасета (для примера)
├── find_similarities  --папака с изображениями, для которых необходимо найти похожие и разделить по отдельным папкам (для примера)
└── paintings_index.ann - рассчитанные и сохраненные Annoy indexes изображений из папки 'all' (для примера)
